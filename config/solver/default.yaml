optimizer: AdamW

lr_scheduler: step
scheduler_gamma: 0.1

base_lr: 1e-4
weight_decay: 1e-6
backbone_lr_multiplier: 0.1
steps:
  - 100
  - 200

max_iter: 289
checkpoint_period: 1000
use_amp: False